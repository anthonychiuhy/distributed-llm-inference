{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1a786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3d5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://10.215.130.20:11434/api/generate\"\n",
    "PAYLOAD = {\n",
    "    \"model\": \"mistral\",\n",
    "    \"prompt\": \"Write a short poem about AI and Telecoms\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 200,\n",
    "    \"stream\": False \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e01c6727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request start 2025-12-30 18:26:05.745591\n",
      "Request started (client): 2025-12-30 18:26:05.747187\n",
      "Request sent to server: 2025-12-30 18:26:05.749950\n",
      "request sent 2025-12-30 18:26:08.798927\n",
      "Server acknowledged (first byte): 2025-12-30 18:26:08.799342\n",
      "{'model': 'mistral', 'created_at': '2025-12-30T18:26:08.790429511Z', 'response': ' Hello! How can I assist you today? If you have any questions or need help with something, feel free to ask.\\n\\nHere are a few examples of what I can do:\\n\\n1. Answer factual questions: \"What is the capital of France?\"\\n2. Help you learn a new language: \"How do you say \\'hello\\' in Spanish?\"\\n3. Provide explanations on various topics: \"What is quantum physics?\"\\n4. Solve math problems: \"What is the square root of 169?\"\\n5. Give advice and recommendations: \"Which books would you recommend for someone interested in learning about artificial intelligence?\"\\n6. Tell jokes or fun facts: \"Why don\\'t scientists trust atoms? Because they make up everything!\"\\n7. Help with daily tasks: \"Set reminders for me to call my friend at 3 PM.\"', 'done': True, 'done_reason': 'stop', 'context': [3, 29473, 23325, 4, 29473, 23325, 29576, 2370, 1309, 1083, 6799, 1136, 3922, 29572, 1815, 1136, 1274, 1475, 4992, 1210, 1695, 2084, 1163, 2313, 29493, 2369, 2701, 1066, 2228, 29491, 781, 781, 16191, 1228, 1032, 2432, 10022, 1070, 1535, 1083, 1309, 1279, 29515, 781, 781, 29508, 29491, 27075, 2407, 1608, 4992, 29515, 1113, 3963, 1117, 1040, 6333, 1070, 5611, 1878, 781, 29518, 29491, 16344, 1136, 3590, 1032, 1401, 4610, 29515, 1113, 6428, 1279, 1136, 2083, 1232, 22326, 29510, 1065, 10945, 1878, 781, 29538, 29491, 7901, 1315, 11696, 1465, 1124, 4886, 14585, 29515, 1113, 3963, 1117, 11683, 16941, 1878, 781, 29549, 29491, 1086, 6071, 11817, 5186, 29515, 1113, 3963, 1117, 1040, 8698, 6325, 1070, 29473, 29508, 29552, 29542, 1878, 781, 29550, 29491, 16872, 8246, 1072, 19660, 29515, 1113, 27471, 5564, 1450, 1136, 7325, 1122, 3261, 7116, 1065, 5936, 1452, 19046, 11663, 1878, 781, 29552, 29491, 16027, 24640, 1210, 1514, 12180, 29515, 1113, 8406, 1717, 29510, 29475, 15835, 5661, 24989, 29572, 6286, 1358, 1806, 1350, 3673, 3549, 781, 29555, 29491, 16344, 1163, 7558, 10564, 29515, 1113, 2204, 9073, 1172, 1122, 1296, 1066, 1802, 1354, 2600, 1206, 29473, 29538, 10400, 1379], 'total_duration': 3006816873, 'load_duration': 959490546, 'prompt_eval_count': 5, 'prompt_eval_duration': 82455829, 'eval_count': 184, 'eval_duration': 1964305975}\n",
      "response_complete 2025-12-30 18:26:08.799577\n",
      "Request 0: Server received in 3053.39ms\n"
     ]
    }
   ],
   "source": [
    "class TimingTrace(aiohttp.TraceConfig):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.timings = {}\n",
    "        self.on_request_start.append(self.on_request_start_callback)\n",
    "        self.on_request_chunk_sent.append(self.on_request_chunk_sent_callback)\n",
    "        self.on_response_chunk_received.append(self.on_response_start_callback)\n",
    "    \n",
    "    async def on_request_start_callback(self, session, context, params):\n",
    "        context.request_start = datetime.now()\n",
    "        print(f\"Request started (client): {context.request_start}\")\n",
    "    \n",
    "    async def on_request_chunk_sent_callback(self, session, context, params):\n",
    "        context.request_sent = datetime.now()\n",
    "        print(f\"Request sent to server: {context.request_sent}\")\n",
    "    \n",
    "    async def on_response_start_callback(self, session, context, params):\n",
    "        context.server_received = datetime.now()\n",
    "        print(f\"Server acknowledged (first byte): {context.server_received}\")\n",
    "\n",
    "async def send_request_with_timing(request_id, prompt):\n",
    "    trace_config = TimingTrace()\n",
    "\n",
    "    url = API_URL\n",
    "    payload = {\n",
    "        \"model\": \"mistral\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    async with aiohttp.ClientSession(trace_configs=[trace_config]) as session:\n",
    "        \n",
    "        client_send_time = datetime.now()\n",
    "\n",
    "        print(\"request start\", datetime.now())\n",
    "        \n",
    "        async with session.post(url, json=payload) as response:\n",
    "            # Server has received and started processing\n",
    "            server_ack_time = datetime.now()\n",
    "            print(\"request sent\", server_ack_time)\n",
    "            \n",
    "            data = await response.json()\n",
    "            print(data)\n",
    "            response_complete_time = datetime.now()\n",
    "            print(\"response_complete\", response_complete_time)\n",
    "            \n",
    "            return {\n",
    "                \"id\": request_id,\n",
    "                \"client_send\": client_send_time,\n",
    "                \"server_ack\": server_ack_time,  # This is when server received it\n",
    "                \"response_complete\": response_complete_time,\n",
    "                \"time_to_server\": (server_ack_time - client_send_time).total_seconds()\n",
    "            }\n",
    "\n",
    "async def traffic_generator(num_requests, prompt):\n",
    "    tasks = [send_request_with_timing(i, prompt) for i in range(num_requests)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Run\n",
    "results = await traffic_generator(1, \"Hello\")\n",
    "for r in results:\n",
    "    print(f\"Request {r['id']}: Server received in {r['time_to_server']*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e507c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request started: 2025-12-31 17:16:02.777273\n",
      "Also Request started (UTC): 2025-12-31 17:16:02.777868\n",
      "Request ended/ack received (UTC): 2025-12-31 17:16:02.817682\n",
      "Also received_at (UTC): 2025-12-31 17:16:02.817757\n",
      "Elapsed seconds: 0.03983436799899209\n",
      "Server Date: Wed, 31 Dec 2025 17:16:02 GMT\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "timings = {}\n",
    "\n",
    "async def on_request_start(session, ctx, params):\n",
    "    timings['start_wall'] = datetime.now()\n",
    "    print(\"Also Request started (UTC):\", timings.get('start_wall'))\n",
    "    timings['start_perf'] = time.perf_counter()\n",
    "\n",
    "async def on_request_end(session, ctx, params):\n",
    "    timings['end_wall'] = datetime.now()\n",
    "    print(\"Request ended/ack received (UTC):\", timings.get('end_wall'))\n",
    "    timings['end_perf'] = time.perf_counter()\n",
    "    timings['elapsed_sec'] = timings['end_perf'] - timings['start_perf']\n",
    "\n",
    "trace_config = aiohttp.TraceConfig()\n",
    "trace_config.on_request_start.append(on_request_start)\n",
    "trace_config.on_request_end.append(on_request_end)\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession(trace_configs=[trace_config]) as session:\n",
    "        start_at = datetime.now()\n",
    "        print(\"Request started:\", start_at)\n",
    "        async with session.post(API_URL, json={\"model\": \"llama2\", \"prompt\": \"Hello\", \"stream\": False}) as resp:\n",
    "            # This is when headers have been received\n",
    "            received_at = datetime.now()\n",
    "            print(\"Also received_at (UTC):\", received_at)\n",
    "            server_date_hdr = resp.headers.get(\"Date\")\n",
    "\n",
    "            \n",
    "            print(\"Elapsed seconds:\", timings.get('elapsed_sec'))\n",
    "            print(\"Server Date:\", server_date_hdr)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd232ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 99902.578786815\n",
      "on_request_start 99902.578922236\n",
      "on_request_headers_sent 99902.580588508\n",
      "on_request_chunk_sent 99902.580668303\n",
      "on_request_end 99909.936220615\n",
      "0 status 99909.936331732 200\n",
      "on_response_chunk_received 99909.936359869\n",
      "0 json 99909.936342206 {'model': 'mistral', 'created_at': '2025-12-31T18:07:43.868814899Z', 'response': ' Title: The Evolution and Future of Artificial Intelligence Development\\n\\nArtificial Intelligence (AI) is a revolutionary technology that has transformed numerous industries and aspects of our lives, from self-driving cars to personalized entertainment. This article provides an overview of the development of AI, its current state, and its future prospects.\\n\\n**Origins and Early Development**\\n\\nThe concept of AI can be traced back to the 1950s when computer scientists at Dartmouth College coined the term \"Artificial Intelligence.\" The first AI program, Logic Theorist, was created in 1956 by Allen Newell and Herbert Simon. It could prove new mathematical theorems in symbolic logic, marking a significant milestone in AI\\'s infancy.\\n\\nThe following decades saw the development of various AI techniques, including rule-based systems, expert systems, and machine learning algorithms. The 1980s and 1990s were characterized by AI winter, a period of reduced funding and interest due to unmet expectations and technological challenges.\\n\\n**Resurgence: Machine Learning and Deep Learning**\\n\\nThe resurgence of AI began in the early 2000s with advancements in machine learning (ML) and deep learning (DL), subfields of AI that focus on training algorithms to learn patterns from data. Key breakthroughs include Google\\'s AlphaGo, which beat a world champion Go player in 2016, and DeepMind\\'s AlphaZero, which taught itself to play various games at superhuman levels without human intervention.\\n\\n**Current State of AI Development**\\n\\nToday, AI is ubiquitous, with applications ranging from virtual assistants like Siri and Alexa to advanced recommendation systems used by Netflix and Amazon. AI is also being applied in healthcare, finance, and autonomous vehicles, among other sectors. However, challenges remain, including ensuring AI\\'s transparency, fairness, and accountability, as well as addressing privacy concerns and ethical dilemmas.\\n\\n**Future Prospects of AI Development**\\n\\nThe future of AI development is promising but complex. Key trends include the rise of edge AI, which allows AI to process data locally on devices instead of relying on cloud servers; the integration of AI with other technologies like blockchain and quantum computing; and the continued focus on solving real-world problems through AI applications.\\n\\nHowever, the future of AI also raises significant societal questions. How will jobs be affected as AI becomes more capable? What ethical guidelines should govern AI\\'s use? Addressing these questions will be crucial for ensuring that AI benefits society as a whole.\\n\\nIn conclusion, AI has come a long way since its inception and continues to evolve at an incredible pace. Its impact on various industries is profound, yet challenges remain in areas such as ethics, transparency, and fairness. As we move forward, it\\'s essential to strike a balance between technological advancement and responsible development of AI for the benefit of all.', 'done': True, 'done_reason': 'stop', 'context': [3, 29473, 12786, 1296, 1164, 6215, 1452, 16875, 4867, 4, 29473, 14391, 29515, 1183, 6508, 2868, 1072, 19010, 1070, 4719, 15541, 23859, 11108, 781, 781, 11131, 15541, 23859, 1093, 12509, 29499, 1117, 1032, 25212, 6282, 1137, 1427, 19020, 10464, 18677, 1072, 11704, 1070, 1581, 5389, 29493, 1245, 1776, 29501, 29483, 17750, 9068, 1066, 4095, 2100, 15943, 29491, 1619, 6215, 6080, 1164, 23862, 1070, 1040, 4867, 1070, 16875, 29493, 1639, 2636, 2433, 29493, 1072, 1639, 4205, 26908, 29491, 781, 781, 1116, 2996, 1094, 1894, 1072, 12906, 11108, 1116, 781, 781, 1782, 6703, 1070, 16875, 1309, 1115, 1235, 3469, 1620, 1066, 1040, 29473, 29508, 29542, 29550, 29502, 29481, 1507, 6842, 15835, 1206, 1152, 1212, 20891, 6904, 1769, 2079, 1040, 2618, 1113, 11131, 15541, 23859, 1379, 1183, 1675, 16875, 2775, 29493, 6313, 1062, 1183, 1039, 1160, 29493, 1171, 4627, 1065, 29473, 29508, 29542, 29550, 29552, 1254, 14963, 2218, 1247, 1072, 24880, 11358, 29491, 1429, 1597, 8442, 1401, 28008, 1040, 1199, 1801, 1065, 6370, 1062, 12176, 29493, 2484, 1056, 1032, 6632, 2888, 19325, 1065, 16875, 29510, 29481, 5087, 6171, 29491, 781, 781, 1782, 3064, 10841, 3440, 1040, 4867, 1070, 4886, 16875, 10572, 29493, 3258, 6686, 29501, 6295, 5686, 29493, 8351, 5686, 29493, 1072, 6367, 5936, 19307, 29491, 1183, 29473, 29508, 29542, 29551, 29502, 29481, 1072, 29473, 29508, 29542, 29542, 29502, 29481, 1422, 23868, 1254, 16875, 9307, 29493, 1032, 3984, 1070, 10165, 12899, 1072, 2913, 3708, 1066, 1289, 3011, 14647, 1072, 27283, 11137, 29491, 781, 781, 1116, 1914, 3589, 1404, 29515, 14021, 18272, 1072, 15740, 18272, 1116, 781, 781, 1782, 1373, 3589, 1404, 1070, 16875, 3893, 1065, 1040, 3703, 29473, 29518, 29502, 29502, 29502, 29481, 1163, 9438, 2107, 1065, 6367, 5936, 1093, 4595, 29499, 1072, 4302, 5936, 1093, 14916, 1325, 1851, 8202, 1070, 16875, 1137, 4000, 1124, 4922, 19307, 1066, 3590, 12301, 1245, 1946, 29491, 8156, 2489, 15736, 29481, 3792, 6950, 29510, 29481, 27678, 8348, 29493, 1458, 9007, 1032, 2294, 13032, 3955, 5153, 1065, 29473, 29518, 29502, 29508, 29552, 29493, 1072, 15740, 29523, 1275, 29510, 29481, 27678, 15605, 29493, 1458, 10389, 4605, 1066, 1924, 4886, 4665, 1206, 2963, 19297, 6925, 2439, 3698, 21056, 29491, 781, 781, 1116, 6854, 4653, 1070, 16875, 11108, 1116, 781, 781, 29506, 20529, 29493, 16875, 1117, 16947, 3509, 1047, 1375, 29493, 1163, 9197, 23509, 1245, 9020, 6799, 2317, 1505, 9119, 29478, 1072, 5781, 29476, 1066, 10791, 26845, 5686, 2075, 1254, 26374, 1072, 9469, 29491, 16875, 1117, 1603, 2018, 8357, 1065, 16008, 29493, 16746, 29493, 1072, 25777, 1375, 12767, 29493, 4120, 1567, 23782, 29491, 3761, 29493, 11137, 7112, 29493, 3258, 20851, 16875, 29510, 29481, 1971, 24535, 29493, 5736, 2235, 29493, 1072, 3476, 3205, 29493, 1158, 1930, 1158, 25411, 13685, 11632, 1072, 27092, 1049, 1314, 3989, 1061, 29491, 781, 781, 1116, 17915, 1901, 7770, 29481, 1070, 16875, 11108, 1116, 781, 781, 1782, 4205, 1070, 16875, 4867, 1117, 23217, 1330, 5398, 29491, 8156, 18637, 3792, 1040, 9186, 1070, 6126, 16875, 29493, 1458, 6744, 16875, 1066, 2527, 1946, 18368, 1124, 9077, 4287, 1070, 1080, 4857, 1124, 7713, 19283, 29513, 1040, 15446, 1070, 16875, 1163, 1567, 15648, 1505, 3492, 9900, 1072, 11683, 22031, 29513, 1072, 1040, 6085, 4000, 1124, 22868, 2121, 29501, 10239, 5186, 1827, 16875, 9197, 29491, 781, 781, 28723, 29493, 1040, 4205, 1070, 16875, 1603, 27489, 6632, 26517, 1050, 4992, 29491, 2370, 1390, 8562, 1115, 11948, 1158, 16875, 7523, 1448, 11405, 29572, 2592, 27092, 19160, 1791, 3179, 16875, 29510, 29481, 1706, 29572, 13814, 1056, 1935, 4992, 1390, 1115, 13808, 1122, 20851, 1137, 16875, 7964, 6958, 1158, 1032, 3662, 29491, 781, 781, 1425, 13654, 29493, 16875, 1427, 2335, 1032, 1811, 1837, 2622, 1639, 1065, 2045, 1072, 11120, 1066, 1451, 6071, 1206, 1164, 14746, 14449, 29491, 8035, 5856, 1124, 4886, 18677, 1117, 20095, 29493, 3551, 11137, 7112, 1065, 5788, 2027, 1158, 8279, 1831, 29493, 1971, 24535, 29493, 1072, 5736, 2235, 29491, 1904, 1246, 3086, 4582, 29493, 1146, 29510, 29481, 8742, 1066, 12872, 1032, 8641, 2212, 27283, 9438, 1234, 1072, 8100, 4867, 1070, 16875, 1122, 1040, 8717, 1070, 1312, 29491], 'total_duration': 7325747605, 'load_duration': 31853951, 'prompt_eval_count': 11, 'prompt_eval_duration': 26549398, 'eval_count': 643, 'eval_duration': 7265729598}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def on_request_start(session, ctx, params):\n",
    "    print(\"on_request_start\", time.perf_counter())\n",
    "\n",
    "async def on_request_headers_sent(session, ctx, params):\n",
    "    print(\"on_request_headers_sent\", time.perf_counter())\n",
    "\n",
    "async def on_request_chunk_sent(session, ctx, params):\n",
    "    print(\"on_request_chunk_sent\", time.perf_counter())\n",
    "\n",
    "async def on_request_end(session, ctx, params):\n",
    "    print(\"on_request_end\", time.perf_counter())\n",
    "\n",
    "async def on_response_chunk_received(session, ctx, params):\n",
    "    print(\"on_response_chunk_received\", time.perf_counter())\n",
    "\n",
    "\n",
    "\n",
    "trace_config = aiohttp.TraceConfig()\n",
    "trace_config.on_request_start.append(on_request_start)\n",
    "trace_config.on_request_headers_sent.append(on_request_headers_sent)\n",
    "trace_config.on_request_chunk_sent.append(on_request_chunk_sent)\n",
    "trace_config.on_request_end.append(on_request_end)\n",
    "trace_config.on_response_chunk_received.append(on_response_chunk_received)\n",
    "\n",
    "\n",
    "async def call(id):\n",
    "    async with aiohttp.ClientSession(trace_configs=[trace_config]) as session:\n",
    "        print(id, time.perf_counter())\n",
    "        async with session.post(API_URL, json={\"model\": \"mistral\", \"prompt\": \"Write me an article about AI development\", \"stream\": False}) as resp:\n",
    "            print(id, \"status\", time.perf_counter(), resp.status)\n",
    "            print(id, \"json\", time.perf_counter(), await resp.json())\n",
    "\n",
    "await asyncio.gather(*(call(i) for i in range(1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distributed-llm (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
